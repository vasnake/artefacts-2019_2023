# default, from /usr/lib/spark/conf/log4j.properties
# Set everything to be logged to the console
log4j.appender.console=org.apache.log4j.ConsoleAppender
log4j.appender.console.target=System.err
log4j.appender.console.layout=org.apache.log4j.PatternLayout
log4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n

log4j.rootCategory=INFO, console
log4j.logger.org.apache.spark.repl.Main=WARN
log4j.logger.org.spark_project.jetty=WARN
log4j.logger.org.spark_project.jetty.util.component.AbstractLifeCycle=ERROR
log4j.logger.org.apache.spark.repl.SparkIMain$exprTyper=INFO
log4j.logger.org.apache.spark.repl.SparkILoop$SparkILoopInterpreter=INFO
log4j.logger.org.apache.parquet=ERROR
log4j.logger.parquet=ERROR
log4j.logger.org.apache.spark.scheduler.DAGScheduler=WARN
log4j.logger.org.apache.spark.storage.memory.MemoryStore=WARN
log4j.logger.org.apache.spark.ContextCleaner=WARN
log4j.logger.org.apache.spark.storage.BlockManager=WARN
log4j.logger.org.apache.spark.storage.BlockManagerMasterEndpoint=WARN
log4j.logger.org.apache.spark.storage.BlockManagerInfo=WARN
log4j.logger.org.apache.spark.deploy.yarn.YarnAllocator=WARN
log4j.logger.org.apache.spark.deploy.yarn.SparkRackResolver=WARN
log4j.logger.org.apache.hadoop.hive.ql.metadata.Hive=WARN
log4j.logger.org.apache.hadoop.hive.ql.metadata=WARN
log4j.logger.org.apache.spark.util.ShutdownHookManager=WARN
log4j.logger.org.apache.spark.scheduler.TaskSetManager=WARN
log4j.logger.org.apache.hadoop.hive.metastore.RetryingHMSHandler=FATAL
log4j.logger.org.apache.hadoop.hive.ql.exec.FunctionRegistry=ERROR

# my logs (com.github.vasnake)
log4j.appender.vasnake=org.apache.log4j.ConsoleAppender
log4j.appender.vasnake.target=System.out
log4j.appender.vasnake.layout=org.apache.log4j.PatternLayout
log4j.appender.vasnake.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} - %p - %c{1} - %m%n

log4j.logger.com.github.vasnake=DEBUG, vasnake
# add my logs to other (ancestors) loggers
log4j.additivity.com.github.vasnake=true
