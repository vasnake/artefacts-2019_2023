{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# catalyst udf/udaf tests (spark2.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "from pprint import pformat\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pprint.pprint(dict(os.environ), width=1)\n",
    "def log(msg, obj=None):\n",
    "    if obj is None:\n",
    "        print(msg)\n",
    "    else:\n",
    "        print(\"{} obj type: {}, obj data:\\n{}\".format(msg, type(obj), pformat(obj, indent=1, width=1)))\n",
    "\n",
    "log(\"os.environ:\", os.environ)\n",
    "log(\"\\ndict(os.environ):\", dict(os.environ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Pack executable conda environment into zip\n",
    "TMP_ENV_BASEDIR = \"tmpenv\"  # Reserved directory to store environment archive\n",
    "env_dir = os.path.dirname(os.path.dirname(sys.executable))\n",
    "env_name = os.path.basename(env_dir)\n",
    "env_archive = \"{basedir}/{env}.zip#{basedir}\".format(basedir=TMP_ENV_BASEDIR, env=env_name)\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"{}/{}/bin/python\".format(TMP_ENV_BASEDIR, env_name)\n",
    "\n",
    "log(\"env_dir:\", env_dir)\n",
    "\n",
    "# you need this only the first time!\n",
    "# !rm -rf {TMP_ENV_BASEDIR} && mkdir {TMP_ENV_BASEDIR} && cd {TMP_ENV_BASEDIR} && rsync -a {env_dir} . && zip -rq {env_name}.zip {env_name}\n",
    "\n",
    "# session builder.config(\"spark.yarn.dist.archives\", env_archive)\n",
    "log(\"env_archive: \", env_archive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<pyspark.sql.session.SparkSession at 0x7f03a4ca9ed0>,\n",
       " <pyspark.sql.context.SQLContext at 0x7f044c5cd8d0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, SQLContext\n",
    "\n",
    "# Create Spark session with conda environment and JVM extensions\n",
    "# `spark-submit ... --driver-java-options \"-Dlog4j.configuration=file:/home/vlk/driver_log4j.properties\"`\n",
    "\n",
    "jira_ticket = \"N-102772\"\n",
    "\n",
    "queue = \"root.dev.one.priority\"\n",
    "\n",
    "# \"spark.driver.extraJavaOptions\", \"-Xss10M\"\n",
    "# catalyst SO while building parts. filter expression\n",
    "\n",
    "sssp = (1 * 4) * 2 * 2 * 4 # 1 GB of data\n",
    "# sssp = (300 * 4) * 2 * 2 # 300 GB\n",
    "\n",
    "spark = (\n",
    "SparkSession.builder\n",
    "    .master(\"yarn-client\")\n",
    "    .appName(\"{}-test-ipynb\".format(jira_ticket))\n",
    "    .config(\"spark.yarn.queue\", queue)\n",
    "    .config(\"spark.sql.shuffle.partitions\", sssp)\n",
    "    .config(\"spark.yarn.dist.archives\", env_archive)\n",
    "    .config(\"spark.executor.instances\", \"2\")\n",
    "    .config(\"spark.executor.cores\", \"6\")\n",
    "    .config(\"spark.executor.memory\", \"6G\")\n",
    "    .config(\"spark.executor.memoryOverhead\", \"6G\")\n",
    "    .config(\"spark.driver.memory\", \"4G\")\n",
    "    .config(\"spark.driver.maxResultSize\", \"2G\")\n",
    "    .config(\"spark.driver.extraJavaOptions\", \"-Dlog4j.configuration=file:/home/vlk/driver2_log4j.properties\")\n",
    "    .config(\"spark.speculation\", \"true\")\n",
    "    .config(\"spark.dynamicAllocation.enabled\", \"true\")\n",
    "    .config(\"spark.dynamicAllocation.minExecutors\", \"2\")\n",
    "    .config(\"spark.dynamicAllocation.maxExecutors\", \"256\")\n",
    "    .config(\"spark.dynamicAllocation.executorIdleTimeout\", \"300s\")\n",
    "    .config(\"spark.network.timeout\", \"800s\")\n",
    "    .config(\"spark.reducer.maxReqsInFlight\", \"10\")\n",
    "    .config(\"spark.shuffle.io.retryWait\", \"60s\")\n",
    "    .config(\"spark.shuffle.io.maxRetries\", \"10\")\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"1024m\")\n",
    "    .config(\"spark.hadoop.hive.exec.dynamic.partition\", \"true\")\n",
    "    .config(\"spark.hadoop.hive.exec.dynamic.partition.mode\", \"nonstrict\")\n",
    "    .config(\"spark.hadoop.hive.exec.max.dynamic.partitions\", \"1000000\")\n",
    "    .config(\"spark.hadoop.hive.exec.max.dynamic.partitions.pernode\", \"100000\")\n",
    "    .config(\"spark.hadoop.hive.metastore.client.socket.timeout\", \"60s\")\n",
    "    .config(\"spark.ui.enabled\", \"true\")\n",
    "    .config(\"spark.sql.sources.partitionColumnTypeInference.enabled\", \"false\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "# .config(\"spark.driver.extraJavaOptions\", \"-Xss10M -Dlog4j.configuration=file:/home/vlk/driver_log4j.properties\")\n",
    "# .config(\"spark.jars\", \"hdfs:/lib/transformers-assembly-SNAPSHOT.jar\")\n",
    "\n",
    "sql_ctx = SQLContext(spark.sparkContext)\n",
    "(spark, sql_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(spark._repr_html_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# end of env. setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "from operator import and_\n",
    "from collections import defaultdict\n",
    "\n",
    "import six\n",
    "import luigi\n",
    "import pyspark\n",
    "import pyspark.sql.functions as sqlfn\n",
    "\n",
    "import json\n",
    "import itertools as it\n",
    "\n",
    "if six.PY3:\n",
    "    from functools import reduce  # make flake8 happy\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from pprint import pformat\n",
    "\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "\n",
    "from pyspark.sql import DataFrame, SQLContext\n",
    "from pyspark.sql.types import (\n",
    "    MapType, ArrayType, FloatType, DoubleType, StringType, StructType, IntegralType, IntegerType, NumericType\n",
    ")\n",
    "from pyspark.sql.utils import CapturedException\n",
    "\n",
    "from pyspark.ml.wrapper import JavaWrapper\n",
    "\n",
    "# from luigi.contrib.hdfs import HdfsTarget\n",
    "\n",
    "from dmgrinder.common.hive import HiveMetastoreClient, HiveThriftSASLContext\n",
    "from dmgrinder.apps.utils.common import add_days\n",
    "from dmgrinder.apps.utils.common import unfreeze_json_param\n",
    "from dmgrinder.apps.utils.common.hive import format_table, select_clause\n",
    "from dmgrinder.apps.utils.common.hive import FindPartitionsEngine\n",
    "from dmgrinder.apps.utils.common.external_program import AvoidLuigiFlatTaskRunner\n",
    "from dmgrinder.apps.utils.common.fs import HdfsClient\n",
    "from dmgrinder.apps.utils.common.luigix import HiveTableSchemaTarget\n",
    "from dmgrinder.apps.utils.common.luigix import HiveExternalTask, HiveGenericTarget\n",
    "from dmgrinder.apps.utils.control.client.logs import ControlLoggingMixin\n",
    "from dmgrinder.apps.utils.control.luigix import ControlApp, ControlDynamicOutputPySparkTask\n",
    "\n",
    "from dmgrinder.apps.utils.common.spark import (\n",
    "    GrinderUDFLibrary,\n",
    "    union_all,\n",
    "    join_filter,\n",
    "    read_orc_table,\n",
    "    configured_join,\n",
    "    insert_into_hive,\n",
    "    stratified_sample,\n",
    "    column_values_count,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "UDFLibrary(spark, \"hdfs:/lib/transformers-assembly-dev-SNAPSHOT.jar\").register_all_udf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(\n",
    "    data=[(\n",
    "        str(i), \n",
    "        \"an{}\".format(i), \n",
    "        \"positive\", \n",
    "        \"ut{}\".format(i % 3), \n",
    "        i,\n",
    "        float(i),\n",
    "        [float(i) / float(x+1) for x in range(7)],\n",
    "        {str(k): float(i) / float(k+1) for k in range(7)},\n",
    "    ) for i in range(1, 123001)],\n",
    "    schema=(\n",
    "        \"uid:string,audience_name:string,category:string,uid_type:string,\"\n",
    "        \"action_dt:long,score:float,score_list:array<float>,score_map:map<string,float>\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hdfs_home_dir = \"hdfs:/user/vlk/\"\n",
    "hdfs_dir = os.path.join(hdfs_home_dir, jira_ticket, \"test_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.repartition(12, \"uid\").write.option(\"mapreduce.fileoutputcommitter.algorithm.version\", \"2\").parquet(\n",
    "    hdfs_dir, mode=\"overwrite\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- uid: string (nullable = true)\n",
      " |-- audience_name: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- uid_type: string (nullable = true)\n",
      " |-- action_dt: long (nullable = true)\n",
      " |-- score: float (nullable = true)\n",
      " |-- score_list: array (nullable = true)\n",
      " |    |-- element: float (containsNull = true)\n",
      " |-- score_map: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: float (valueContainsNull = true)\n",
      "\n",
      "+---+-------------+--------+--------+---------+-----+--------------------+--------------------+\n",
      "|uid|audience_name|category|uid_type|action_dt|score|          score_list|           score_map|\n",
      "+---+-------------+--------+--------+---------+-----+--------------------+--------------------+\n",
      "| 20|         an20|positive|     ut2|       20| 20.0|[20.0, 10.0, 6.66...|[0 -> 20.0, 1 -> ...|\n",
      "| 27|         an27|positive|     ut0|       27| 27.0|[27.0, 13.5, 9.0,...|[0 -> 27.0, 1 -> ...|\n",
      "| 36|         an36|positive|     ut0|       36| 36.0|[36.0, 18.0, 12.0...|[0 -> 36.0, 1 -> ...|\n",
      "| 69|         an69|positive|     ut0|       69| 69.0|[69.0, 34.5, 23.0...|[0 -> 69.0, 1 -> ...|\n",
      "| 70|         an70|positive|     ut1|       70| 70.0|[70.0, 35.0, 23.3...|[0 -> 70.0, 1 -> ...|\n",
      "| 81|         an81|positive|     ut0|       81| 81.0|[81.0, 40.5, 27.0...|[0 -> 81.0, 1 -> ...|\n",
      "|121|        an121|positive|     ut1|      121|121.0|[121.0, 60.5, 40....|[0 -> 121.0, 1 ->...|\n",
      "|126|        an126|positive|     ut0|      126|126.0|[126.0, 63.0, 42....|[0 -> 126.0, 1 ->...|\n",
      "|131|        an131|positive|     ut2|      131|131.0|[131.0, 65.5, 43....|[0 -> 131.0, 1 ->...|\n",
      "|140|        an140|positive|     ut2|      140|140.0|[140.0, 70.0, 46....|[0 -> 140.0, 1 ->...|\n",
      "+---+-------------+--------+--------+---------+-----+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(hdfs_dir)  # .persist()\n",
    "df.printSchema()\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def show(df):\n",
    "    df.printSchema()\n",
    "    df.explain()\n",
    "    df.show(truncate=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gmin, gmax, gsum, gavg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "exprs = [sqlfn.expr(expr) for expr in [\n",
    "    \"gmin(score) as score\", \n",
    "    \"gmax(score_list)\", \n",
    "    \"gmin(score_map)\", \n",
    "    \"gsum(score)\",\n",
    "    \"gsum(score_list)\",\n",
    "    \"gsum(score_map)\",\n",
    "    \"gavg(score)\",\n",
    "    \"gavg(score_list)\",\n",
    "    \"gavg(score_map)\",\n",
    "]]\n",
    "\n",
    "_df = df.where(\"uid_type in ('ut2', 'ut1')\").groupBy(\"uid_type\").agg(*exprs).where(\"score < 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- uid_type: string (nullable = true)\n",
      " |-- score: float (nullable = true)\n",
      " |-- gmax(score_list): array (nullable = true)\n",
      " |    |-- element: float (containsNull = true)\n",
      " |-- gmin(score_map): map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: float (valueContainsNull = true)\n",
      " |-- gsum(score): float (nullable = true)\n",
      " |-- gsum(score_list): array (nullable = true)\n",
      " |    |-- element: float (containsNull = true)\n",
      " |-- gsum(score_map): map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: float (valueContainsNull = true)\n",
      " |-- gavg(score): float (nullable = true)\n",
      " |-- gavg(score_list): array (nullable = true)\n",
      " |    |-- element: float (containsNull = true)\n",
      " |-- gavg(score_map): map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: float (valueContainsNull = true)\n",
      "\n",
      "+--------+-----+-----------------------------------------------------------------------+--------------------------------------------------------------------------------------------+------------+-----------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------+-----------+-----------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------+\n",
      "|uid_type|score|gmax(score_list)                                                       |gmin(score_map)                                                                             |gsum(score) |gsum(score_list)                                                                               |gsum(score_map)                                                                                                                   |gavg(score)|gavg(score_list)                                                       |gavg(score_map)                                                                                           |\n",
      "+--------+-----+-----------------------------------------------------------------------+--------------------------------------------------------------------------------------------+------------+-----------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------+-----------+-----------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------+\n",
      "|ut2     |2.0  |[122999.0, 61499.5, 40999.668, 30749.75, 24599.8, 20499.834, 17571.285]|[4 -> 0.4, 5 -> 0.33333334, 6 -> 0.2857143, 0 -> 2.0, 2 -> 0.6666667, 3 -> 0.5, 1 -> 1.0]   |2.52152038E9|[2.52152038E9, 1.26076019E9, 8.4050682E8, 6.303801E8, 5.04304096E8, 4.20253408E8, 3.60217216E8]|[4 -> 5.04304096E8, 5 -> 4.20253408E8, 6 -> 3.60217216E8, 0 -> 2.52152038E9, 2 -> 8.4050682E8, 3 -> 6.303801E8, 1 -> 1.26076019E9]|61500.5    |[61500.5, 30750.25, 20500.166, 15375.125, 12300.1, 10250.083, 8785.786]|[4 -> 12300.1, 5 -> 10250.083, 6 -> 8785.786, 0 -> 61500.5, 2 -> 20500.166, 3 -> 15375.125, 1 -> 30750.25]|\n",
      "|ut1     |1.0  |[122998.0, 61499.0, 40999.332, 30749.5, 24599.6, 20499.666, 17571.143] |[4 -> 0.2, 5 -> 0.16666667, 6 -> 0.14285715, 0 -> 1.0, 2 -> 0.33333334, 3 -> 0.25, 1 -> 0.5]|2.52147942E9|[2.52147942E9, 1.26073971E9, 8.4049318E8, 6.3036986E8, 5.04295904E8, 4.20246592E8, 3.6021136E8]|[4 -> 5.04295904E8, 5 -> 4.20246592E8, 6 -> 3.6021136E8, 0 -> 2.52147942E9, 2 -> 8.4049318E8, 3 -> 6.3036986E8, 1 -> 1.26073971E9]|61499.5    |[61499.5, 30749.75, 20499.834, 15374.875, 12299.9, 10249.917, 8785.643]|[4 -> 12299.9, 5 -> 10249.917, 6 -> 8785.643, 0 -> 61499.5, 2 -> 20499.834, 3 -> 15374.875, 1 -> 30749.75]|\n",
      "+--------+-----+-----------------------------------------------------------------------+--------------------------------------------------------------------------------------------+------------+-----------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------+-----------+-----------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "== Physical Plan ==\n",
      "*(2) Filter (isnotnull(score#1061) && (score#1061 < 10.0))\n",
      "+- ObjectHashAggregate(keys=[uid_type#1023], functions=[generic_min(score#1025, 0, 0), generic_max(score_list#1026, 0, 0), generic_min(score_map#1027, 0, 0), generic_sum(score#1025, 0, 0), generic_sum(score_list#1026, 0, 0), generic_sum(score_map#1027, 0, 0), generic_avg(score#1025, 0, 0), generic_avg(score_list#1026, 0, 0), generic_avg(score_map#1027, 0, 0)])\n",
      "   +- Exchange hashpartitioning(uid_type#1023, 64)\n",
      "      +- ObjectHashAggregate(keys=[uid_type#1023], functions=[partial_generic_min(score#1025, 0, 0), partial_generic_max(score_list#1026, 0, 0), partial_generic_min(score_map#1027, 0, 0), partial_generic_sum(score#1025, 0, 0), partial_generic_sum(score_list#1026, 0, 0), partial_generic_sum(score_map#1027, 0, 0), partial_generic_avg(score#1025, 0, 0), partial_generic_avg(score_list#1026, 0, 0), partial_generic_avg(score_map#1027, 0, 0)])\n",
      "         +- *(1) Filter uid_type#1023 IN (ut2,ut1)\n",
      "            +- *(1) FileScan parquet [uid_type#1023,score#1025,score_list#1026,score_map#1027] Batched: false, Format: Parquet, Location: InMemoryFileIndex[hdfs://hacluster/user/v.fedulov/TRG-102772/test_dataset], PartitionFilters: [], PushedFilters: [In(uid_type, [ut2,ut1])], ReadSchema: struct<uid_type:string,score:float,score_list:array<float>,score_map:map<string,float>>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[uid_type: string, score: float, gmax(score_list): array<float>, gmin(score_map): map<string,float>, gsum(score): float, gsum(score_list): array<float>, gsum(score_map): map<string,float>, gavg(score): float, gavg(score_list): array<float>, gavg(score_map): map<string,float>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show(_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### most_freq(column, index=null, threshold=null, prefer=null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exprs = [sqlfn.expr(expr) for expr in [\n",
    "    \"most_freq(score) as score\",\n",
    "    \"most_freq(uid)\",\n",
    "    \"most_freq(action_dt)\",\n",
    "]]\n",
    "\n",
    "_df = df.where(\"uid_type in ('ut2', 'ut1')\").groupBy(\"uid_type\").agg(*exprs).where(\"score != 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- uid_type: string (nullable = true)\n",
      " |-- score: float (nullable = true)\n",
      " |-- most_freq(uid): string (nullable = true)\n",
      " |-- most_freq(action_dt): long (nullable = true)\n",
      "\n",
      "+--------+--------+--------------+--------------------+\n",
      "|uid_type|score   |most_freq(uid)|most_freq(action_dt)|\n",
      "+--------+--------+--------------+--------------------+\n",
      "|ut2     |107603.0|22472         |44723               |\n",
      "|ut1     |787.0   |32071         |21226               |\n",
      "+--------+--------+--------------+--------------------+\n",
      "\n",
      "== Physical Plan ==\n",
      "*(2) Filter (isnotnull(score#1189) && NOT (score#1189 = 10.0))\n",
      "+- ObjectHashAggregate(keys=[uid_type#1023], functions=[generic_most_freq(score#1025, null, null, null, 0, 0), generic_most_freq(uid#1020, null, null, null, 0, 0), generic_most_freq(action_dt#1024L, null, null, null, 0, 0)])\n",
      "   +- Exchange hashpartitioning(uid_type#1023, 64)\n",
      "      +- ObjectHashAggregate(keys=[uid_type#1023], functions=[partial_generic_most_freq(score#1025, null, null, null, 0, 0), partial_generic_most_freq(uid#1020, null, null, null, 0, 0), partial_generic_most_freq(action_dt#1024L, null, null, null, 0, 0)])\n",
      "         +- *(1) Filter uid_type#1023 IN (ut2,ut1)\n",
      "            +- *(1) FileScan parquet [uid#1020,uid_type#1023,action_dt#1024L,score#1025] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://hacluster/user/v.fedulov/TRG-102772/test_dataset], PartitionFilters: [], PushedFilters: [In(uid_type, [ut2,ut1])], ReadSchema: struct<uid:string,uid_type:string,action_dt:bigint,score:float>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[uid_type: string, score: float, most_freq(uid): string, most_freq(action_dt): bigint]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show(_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### map_values_ordered(map_column, keys_list)\n",
    "Сигнатура: `(map<string, float>, array<string>) => array<float>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- uid: string (nullable = true)\n",
      " |-- score: float (nullable = true)\n",
      " |-- UDF:map_values_ordered(score_map, array(1, 2, 3)): array (nullable = true)\n",
      " |    |-- element: float (containsNull = true)\n",
      "\n",
      "+---+-----+-------------------------------------------------+\n",
      "|uid|score|UDF:map_values_ordered(score_map, array(1, 2, 3))|\n",
      "+---+-----+-------------------------------------------------+\n",
      "|20 |20.0 |[10.0, 6.6666665, 5.0]                           |\n",
      "|70 |70.0 |[35.0, 23.333334, 17.5]                          |\n",
      "|121|121.0|[60.5, 40.333332, 30.25]                         |\n",
      "|131|131.0|[65.5, 43.666668, 32.75]                         |\n",
      "|140|140.0|[70.0, 46.666668, 35.0]                          |\n",
      "|152|152.0|[76.0, 50.666668, 38.0]                          |\n",
      "|158|158.0|[79.0, 52.666668, 39.5]                          |\n",
      "|200|200.0|[100.0, 66.666664, 50.0]                         |\n",
      "|202|202.0|[101.0, 67.333336, 50.5]                         |\n",
      "|218|218.0|[109.0, 72.666664, 54.5]                         |\n",
      "|223|223.0|[111.5, 74.333336, 55.75]                        |\n",
      "|269|269.0|[134.5, 89.666664, 67.25]                        |\n",
      "|277|277.0|[138.5, 92.333336, 69.25]                        |\n",
      "|295|295.0|[147.5, 98.333336, 73.75]                        |\n",
      "|314|314.0|[157.0, 104.666664, 78.5]                        |\n",
      "|347|347.0|[173.5, 115.666664, 86.75]                       |\n",
      "|365|365.0|[182.5, 121.666664, 91.25]                       |\n",
      "|370|370.0|[185.0, 123.333336, 92.5]                        |\n",
      "|388|388.0|[194.0, 129.33333, 97.0]                         |\n",
      "|389|389.0|[194.5, 129.66667, 97.25]                        |\n",
      "+---+-----+-------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "== Physical Plan ==\n",
      "*(1) Project [uid#1020, score#1025, UDF:map_values_ordered(score_map#1027, [1,2,3]) AS UDF:map_values_ordered(score_map, array(1, 2, 3))#1230]\n",
      "+- *(1) Filter ((isnotnull(score#1025) && uid_type#1023 IN (ut2,ut1)) && NOT (score#1025 = 10.0))\n",
      "   +- *(1) FileScan parquet [uid#1020,uid_type#1023,score#1025,score_map#1027] Batched: false, Format: Parquet, Location: InMemoryFileIndex[hdfs://hacluster/user/v.fedulov/TRG-102772/test_dataset], PartitionFilters: [], PushedFilters: [IsNotNull(score), In(uid_type, [ut2,ut1]), Not(EqualTo(score,10.0))], ReadSchema: struct<uid:string,uid_type:string,score:float,score_map:map<string,float>>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[uid: string, score: float, UDF:map_values_ordered(score_map, array(1, 2, 3)): array<float>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "+---+-------------+--------+--------+---------+-----+--------------------+--------------------+\n",
    "|uid|audience_name|category|uid_type|action_dt|score|          score_list|           score_map|\n",
    "+---+-------------+--------+--------+---------+-----+--------------------+--------------------+\n",
    "| 20|         an20|positive|     ut2|       20| 20.0|[20.0, 10.0, 6.66...|[0 -> 20.0, 1 -> ...|\n",
    "\"\"\"\n",
    "exprs = [sqlfn.expr(expr) for expr in [\n",
    "    \"uid\",\n",
    "    \"score\",\n",
    "    \"map_values_ordered(score_map, array('1', '2', '3'))\",\n",
    "]]\n",
    "\n",
    "_df = df.where(\"uid_type in ('ut2', 'ut1')\").select(*exprs).where(\"score != 10\")\n",
    "show(_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### is_uint32(str_column)\n",
    "Сигнатура: `string => boolean`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- uid: string (nullable = true)\n",
      " |-- score: float (nullable = true)\n",
      " |-- UDF:is_uint32(uid): boolean (nullable = true)\n",
      "\n",
      "+---+-----+------------------+\n",
      "|uid|score|UDF:is_uint32(uid)|\n",
      "+---+-----+------------------+\n",
      "|20 |20.0 |true              |\n",
      "|70 |70.0 |true              |\n",
      "|121|121.0|true              |\n",
      "|131|131.0|true              |\n",
      "|140|140.0|true              |\n",
      "|152|152.0|true              |\n",
      "|158|158.0|true              |\n",
      "|200|200.0|true              |\n",
      "|202|202.0|true              |\n",
      "|218|218.0|true              |\n",
      "|223|223.0|true              |\n",
      "|269|269.0|true              |\n",
      "|277|277.0|true              |\n",
      "|295|295.0|true              |\n",
      "|314|314.0|true              |\n",
      "|347|347.0|true              |\n",
      "|365|365.0|true              |\n",
      "|370|370.0|true              |\n",
      "|388|388.0|true              |\n",
      "|389|389.0|true              |\n",
      "+---+-----+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "== Physical Plan ==\n",
      "*(1) Project [uid#1020, score#1025, UDF:is_uint32(uid#1020) AS UDF:is_uint32(uid)#1244]\n",
      "+- *(1) Filter ((isnotnull(score#1025) && uid_type#1023 IN (ut2,ut1)) && NOT (score#1025 = 10.0))\n",
      "   +- *(1) FileScan parquet [uid#1020,uid_type#1023,score#1025] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://hacluster/user/v.fedulov/TRG-102772/test_dataset], PartitionFilters: [], PushedFilters: [IsNotNull(score), In(uid_type, [ut2,ut1]), Not(EqualTo(score,10.0))], ReadSchema: struct<uid:string,uid_type:string,score:float>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[uid: string, score: float, UDF:is_uint32(uid): boolean]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exprs = [sqlfn.expr(expr) for expr in [\n",
    "    \"uid\",\n",
    "    \"score\",\n",
    "    \"is_uint32(uid)\",\n",
    "]]\n",
    "\n",
    "_df = df.where(\"uid_type in ('ut2', 'ut1')\").select(*exprs).where(\"score != 10\")\n",
    "show(_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hash_to_uint32(str_column)\n",
    "Сигнатура: `string => string`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- uid: string (nullable = true)\n",
      " |-- score: float (nullable = true)\n",
      " |-- UDF:hash_to_uint32(audience_name): string (nullable = true)\n",
      "\n",
      "+---+-----+---------------------------------+\n",
      "|uid|score|UDF:hash_to_uint32(audience_name)|\n",
      "+---+-----+---------------------------------+\n",
      "|20 |20.0 |3074177046                       |\n",
      "|70 |70.0 |1572117424                       |\n",
      "|121|121.0|1394285225                       |\n",
      "|131|131.0|1804965547                       |\n",
      "|140|140.0|2520080435                       |\n",
      "|152|152.0|4274212572                       |\n",
      "|158|158.0|1658192223                       |\n",
      "|200|200.0|3196484522                       |\n",
      "|202|202.0|51751845                         |\n",
      "|218|218.0|2839725946                       |\n",
      "|223|223.0|365801713                        |\n",
      "|269|269.0|1146275242                       |\n",
      "|277|277.0|1657397741                       |\n",
      "|295|295.0|910553476                        |\n",
      "|314|314.0|200282540                        |\n",
      "|347|347.0|3551783777                       |\n",
      "|365|365.0|2059818960                       |\n",
      "|370|370.0|1770662356                       |\n",
      "|388|388.0|178032623                        |\n",
      "|389|389.0|1401784578                       |\n",
      "+---+-----+---------------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "== Physical Plan ==\n",
      "*(1) Project [uid#1020, score#1025, UDF:hash_to_uint32(audience_name#1021) AS UDF:hash_to_uint32(audience_name)#1258]\n",
      "+- *(1) Filter ((isnotnull(score#1025) && uid_type#1023 IN (ut2,ut1)) && NOT (score#1025 = 10.0))\n",
      "   +- *(1) FileScan parquet [uid#1020,audience_name#1021,uid_type#1023,score#1025] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://hacluster/user/v.fedulov/TRG-102772/test_dataset], PartitionFilters: [], PushedFilters: [IsNotNull(score), In(uid_type, [ut2,ut1]), Not(EqualTo(score,10.0))], ReadSchema: struct<uid:string,audience_name:string,uid_type:string,score:float>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[uid: string, score: float, UDF:hash_to_uint32(audience_name): string]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "+---+-------------+--------+--------+---------+-----+--------------------+--------------------+\n",
    "|uid|audience_name|category|uid_type|action_dt|score|          score_list|           score_map|\n",
    "+---+-------------+--------+--------+---------+-----+--------------------+--------------------+\n",
    "| 20|         an20|positive|     ut2|       20| 20.0|[20.0, 10.0, 6.66...|[0 -> 20.0, 1 -> ...|\n",
    "\"\"\"\n",
    "exprs = [sqlfn.expr(expr) for expr in [\n",
    "    \"uid\",\n",
    "    \"score\",\n",
    "    \"hash_to_uint32(audience_name)\",\n",
    "]]\n",
    "\n",
    "_df = df.where(\"uid_type in ('ut2', 'ut1')\").select(*exprs).where(\"score != 10\")\n",
    "show(_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### uid64(str_column)\n",
    "Сигнатура: `string => string`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- uid: string (nullable = true)\n",
      " |-- score: float (nullable = true)\n",
      " |-- UDF:uid64(md5(cast(audience_name as binary))): string (nullable = true)\n",
      "\n",
      "+---+-----+---------------------------------------------+\n",
      "|uid|score|UDF:uid64(md5(cast(audience_name as binary)))|\n",
      "+---+-----+---------------------------------------------+\n",
      "|20 |20.0 |10450430168314814339                         |\n",
      "|70 |70.0 |771192226233195387                           |\n",
      "|121|121.0|18367159758826262061                         |\n",
      "|131|131.0|2887395016517913779                          |\n",
      "|140|140.0|8805933726758575420                          |\n",
      "|152|152.0|3018354615061546692                          |\n",
      "|158|158.0|4321784850796573240                          |\n",
      "|200|200.0|8817945939647107112                          |\n",
      "|202|202.0|17848873196591168689                         |\n",
      "|218|218.0|17551919422123190489                         |\n",
      "|223|223.0|15761808761620872783                         |\n",
      "|269|269.0|11441267015519271768                         |\n",
      "|277|277.0|15666910133070823115                         |\n",
      "|295|295.0|1054994894875670897                          |\n",
      "|314|314.0|13672451756553559685                         |\n",
      "|347|347.0|1461468960876599157                          |\n",
      "|365|365.0|12877082213271578268                         |\n",
      "|370|370.0|9766602662209400338                          |\n",
      "|388|388.0|10910148643534620174                         |\n",
      "|389|389.0|16753084477297739309                         |\n",
      "+---+-----+---------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "== Physical Plan ==\n",
      "*(1) Project [uid#1020, score#1025, UDF:uid64(md5(cast(audience_name#1021 as binary))) AS UDF:uid64(md5(cast(audience_name as binary)))#1272]\n",
      "+- *(1) Filter ((isnotnull(score#1025) && uid_type#1023 IN (ut2,ut1)) && NOT (score#1025 = 10.0))\n",
      "   +- *(1) FileScan parquet [uid#1020,audience_name#1021,uid_type#1023,score#1025] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://hacluster/user/v.fedulov/TRG-102772/test_dataset], PartitionFilters: [], PushedFilters: [IsNotNull(score), In(uid_type, [ut2,ut1]), Not(EqualTo(score,10.0))], ReadSchema: struct<uid:string,audience_name:string,uid_type:string,score:float>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[uid: string, score: float, UDF:uid64(md5(cast(audience_name as binary))): string]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "+---+-------------+--------+--------+---------+-----+--------------------+--------------------+\n",
    "|uid|audience_name|category|uid_type|action_dt|score|          score_list|           score_map|\n",
    "+---+-------------+--------+--------+---------+-----+--------------------+--------------------+\n",
    "| 20|         an20|positive|     ut2|       20| 20.0|[20.0, 10.0, 6.66...|[0 -> 20.0, 1 -> ...|\n",
    "\"\"\"\n",
    "exprs = [sqlfn.expr(expr) for expr in [\n",
    "    \"uid\",\n",
    "    \"score\",\n",
    "    \"uid64(md5(audience_name))\",\n",
    "]]\n",
    "\n",
    "_df = df.where(\"uid_type in ('ut2', 'ut1')\").select(*exprs).where(\"score != 10\")\n",
    "show(_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### map_join(map_column, items_separator, kv_separator)\n",
    "Сигнатура: `(map<string, float>, string, string) => string`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- uid: string (nullable = true)\n",
      " |-- score: float (nullable = true)\n",
      " |-- UDF:map_join(score_map, ;, ,): string (nullable = true)\n",
      "\n",
      "+---+-----+-------------------------------------------------------------------+\n",
      "|uid|score|UDF:map_join(score_map, ;, ,)                                      |\n",
      "+---+-----+-------------------------------------------------------------------+\n",
      "|20 |20.0 |4,4.0;5,3.3333333;6,2.857143;1,10.0;0,20.0;2,6.6666665;3,5.0       |\n",
      "|70 |70.0 |4,14.0;5,11.666667;6,10.0;1,35.0;0,70.0;2,23.333334;3,17.5         |\n",
      "|121|121.0|4,24.2;5,20.166666;6,17.285715;1,60.5;0,121.0;2,40.333332;3,30.25  |\n",
      "|131|131.0|4,26.2;5,21.833334;6,18.714285;1,65.5;0,131.0;2,43.666668;3,32.75  |\n",
      "|140|140.0|4,28.0;5,23.333334;6,20.0;1,70.0;0,140.0;2,46.666668;3,35.0        |\n",
      "|152|152.0|4,30.4;5,25.333334;6,21.714285;1,76.0;0,152.0;2,50.666668;3,38.0   |\n",
      "|158|158.0|4,31.6;5,26.333334;6,22.571428;1,79.0;0,158.0;2,52.666668;3,39.5   |\n",
      "|200|200.0|4,40.0;5,33.333332;6,28.571428;1,100.0;0,200.0;2,66.666664;3,50.0  |\n",
      "|202|202.0|4,40.4;5,33.666668;6,28.857143;1,101.0;0,202.0;2,67.333336;3,50.5  |\n",
      "|218|218.0|4,43.6;5,36.333332;6,31.142857;1,109.0;0,218.0;2,72.666664;3,54.5  |\n",
      "|223|223.0|4,44.6;5,37.166668;6,31.857143;1,111.5;0,223.0;2,74.333336;3,55.75 |\n",
      "|269|269.0|4,53.8;5,44.833332;6,38.42857;1,134.5;0,269.0;2,89.666664;3,67.25  |\n",
      "|277|277.0|4,55.4;5,46.166668;6,39.57143;1,138.5;0,277.0;2,92.333336;3,69.25  |\n",
      "|295|295.0|4,59.0;5,49.166668;6,42.142857;1,147.5;0,295.0;2,98.333336;3,73.75 |\n",
      "|314|314.0|4,62.8;5,52.333332;6,44.857143;1,157.0;0,314.0;2,104.666664;3,78.5 |\n",
      "|347|347.0|4,69.4;5,57.833332;6,49.57143;1,173.5;0,347.0;2,115.666664;3,86.75 |\n",
      "|365|365.0|4,73.0;5,60.833332;6,52.142857;1,182.5;0,365.0;2,121.666664;3,91.25|\n",
      "|370|370.0|4,74.0;5,61.666668;6,52.857143;1,185.0;0,370.0;2,123.333336;3,92.5 |\n",
      "|388|388.0|4,77.6;5,64.666664;6,55.42857;1,194.0;0,388.0;2,129.33333;3,97.0   |\n",
      "|389|389.0|4,77.8;5,64.833336;6,55.57143;1,194.5;0,389.0;2,129.66667;3,97.25  |\n",
      "+---+-----+-------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "== Physical Plan ==\n",
      "*(1) Project [uid#1020, score#1025, UDF:map_join(score_map#1027, ;, ,) AS UDF:map_join(score_map, ;, ,)#1300]\n",
      "+- *(1) Filter ((isnotnull(score#1025) && uid_type#1023 IN (ut2,ut1)) && NOT (score#1025 = 10.0))\n",
      "   +- *(1) FileScan parquet [uid#1020,uid_type#1023,score#1025,score_map#1027] Batched: false, Format: Parquet, Location: InMemoryFileIndex[hdfs://hacluster/user/v.fedulov/TRG-102772/test_dataset], PartitionFilters: [], PushedFilters: [IsNotNull(score), In(uid_type, [ut2,ut1]), Not(EqualTo(score,10.0))], ReadSchema: struct<uid:string,uid_type:string,score:float,score_map:map<string,float>>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[uid: string, score: float, UDF:map_join(score_map, ;, ,): string]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "+---+-------------+--------+--------+---------+-----+--------------------+--------------------+\n",
    "|uid|audience_name|category|uid_type|action_dt|score|          score_list|           score_map|\n",
    "+---+-------------+--------+--------+---------+-----+--------------------+--------------------+\n",
    "| 20|         an20|positive|     ut2|       20| 20.0|[20.0, 10.0, 6.66...|[0 -> 20.0, 1 -> ...|\n",
    "\"\"\"\n",
    "exprs = [sqlfn.expr(expr) for expr in [\n",
    "    \"uid\",\n",
    "    \"score\",\n",
    "    \"map_join(score_map, ';', ',')\",\n",
    "]]\n",
    "\n",
    "_df = df.where(\"uid_type in ('ut2', 'ut1')\").select(*exprs).where(\"score != 10\")\n",
    "show(_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### uid2user(uid, uid_type)\n",
    "Сигнатура: `(string, string) => string`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- uid: string (nullable = true)\n",
      " |-- score: float (nullable = true)\n",
      " |-- UDF:uid2user(uid, HID): string (nullable = true)\n",
      "\n",
      "+---+-----+----------------------+\n",
      "|uid|score|UDF:uid2user(uid, HID)|\n",
      "+---+-----+----------------------+\n",
      "|20 |20.0 |hid:20                |\n",
      "|70 |70.0 |hid:70                |\n",
      "|121|121.0|hid:121               |\n",
      "|131|131.0|hid:131               |\n",
      "|140|140.0|hid:140               |\n",
      "|152|152.0|hid:152               |\n",
      "|158|158.0|hid:158               |\n",
      "|200|200.0|hid:200               |\n",
      "|202|202.0|hid:202               |\n",
      "|218|218.0|hid:218               |\n",
      "|223|223.0|hid:223               |\n",
      "|269|269.0|hid:269               |\n",
      "|277|277.0|hid:277               |\n",
      "|295|295.0|hid:295               |\n",
      "|314|314.0|hid:314               |\n",
      "|347|347.0|hid:347               |\n",
      "|365|365.0|hid:365               |\n",
      "|370|370.0|hid:370               |\n",
      "|388|388.0|hid:388               |\n",
      "|389|389.0|hid:389               |\n",
      "+---+-----+----------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "== Physical Plan ==\n",
      "*(1) Project [uid#1020, score#1025, UDF:uid2user(uid#1020, HID) AS UDF:uid2user(uid, HID)#1314]\n",
      "+- *(1) Filter ((isnotnull(score#1025) && uid_type#1023 IN (ut2,ut1)) && NOT (score#1025 = 10.0))\n",
      "   +- *(1) FileScan parquet [uid#1020,uid_type#1023,score#1025] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://hacluster/user/v.fedulov/TRG-102772/test_dataset], PartitionFilters: [], PushedFilters: [IsNotNull(score), In(uid_type, [ut2,ut1]), Not(EqualTo(score,10.0))], ReadSchema: struct<uid:string,uid_type:string,score:float>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[uid: string, score: float, UDF:uid2user(uid, HID): string]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "+---+-------------+--------+--------+---------+-----+--------------------+--------------------+\n",
    "|uid|audience_name|category|uid_type|action_dt|score|          score_list|           score_map|\n",
    "+---+-------------+--------+--------+---------+-----+--------------------+--------------------+\n",
    "| 20|         an20|positive|     ut2|       20| 20.0|[20.0, 10.0, 6.66...|[0 -> 20.0, 1 -> ...|\n",
    "\"\"\"\n",
    "exprs = [sqlfn.expr(expr) for expr in [\n",
    "    \"uid\",\n",
    "    \"score\",\n",
    "    \"uid2user(uid, 'HID')\",\n",
    "]]\n",
    "\n",
    "_df = df.where(\"uid_type in ('ut2', 'ut1')\").select(*exprs).where(\"score != 10\")\n",
    "show(_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### coomul(vec1, vec2); semidiff(vec1, vec2); semisum(vec1, vec2); matmul(vec1, vec2)\n",
    "Сигнатура: `(array<numeric>, array<numeric>) => array<numeric>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- uid: string (nullable = true)\n",
      " |-- score: float (nullable = true)\n",
      " |-- genericvectorcoomul(score_list, score_list): array (nullable = true)\n",
      " |    |-- element: float (containsNull = true)\n",
      " |-- genericvectorsemidiff(score_list, score_list): array (nullable = true)\n",
      " |    |-- element: float (containsNull = true)\n",
      " |-- genericvectorsemisum(score_list, score_list): array (nullable = true)\n",
      " |    |-- element: float (containsNull = true)\n",
      " |-- genericvectormatmul(concat(score_list, array(1, 2)), concat(array(1, 2), score_list)): array (nullable = true)\n",
      " |    |-- element: float (containsNull = true)\n",
      "\n",
      "+---+-----+---------------------------------------------------------------------------+---------------------------------------------+-------------------------------------------------------------+---------------------------------------------------------------------------------------------------+\n",
      "|uid|score|genericvectorcoomul(score_list, score_list)                                |genericvectorsemidiff(score_list, score_list)|genericvectorsemisum(score_list, score_list)                 |genericvectormatmul(concat(score_list, array(1, 2)), concat(array(1, 2), score_list))              |\n",
      "+---+-----+---------------------------------------------------------------------------+---------------------------------------------+-------------------------------------------------------------+---------------------------------------------------------------------------------------------------+\n",
      "|20 |20.0 |[400.0, 100.0, 44.444443, 25.0, 16.0, 11.111111, 8.163265]                 |[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]          |[20.0, 10.0, 6.6666665, 5.0, 4.0, 3.3333333, 2.857143]       |[146.66667, 128.88889, 469.0476, 58.333332, 47.777775, 129.5238, 20.857143, 19.047619, 67.85715]   |\n",
      "|70 |70.0 |[4900.0, 1225.0, 544.44446, 306.25, 196.0, 136.11111, 100.0]               |[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]          |[70.0, 35.0, 23.333334, 17.5, 14.0, 11.666667, 10.0]         |[1621.6666, 1228.8889, 5745.8335, 670.8333, 497.7778, 1586.6666, 73.0, 66.66667, 737.5]            |\n",
      "|121|121.0|[14641.0, 3660.25, 1626.7777, 915.0625, 585.64, 406.69443, 298.79596]      |[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]          |[121.0, 60.5, 40.333332, 30.25, 24.2, 20.166666, 17.285715]  |[4757.317, 3495.5554, 17168.316, 1982.3834, 1443.2611, 4740.8955, 126.185715, 115.2381, 2156.393]  |\n",
      "|131|131.0|[17161.0, 4290.25, 1906.7778, 1072.5625, 686.44006, 476.69446, 350.22446]  |[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]          |[131.0, 65.5, 43.666668, 32.75, 26.2, 21.833334, 18.714285]  |[5565.317, 4075.5557, 20123.316, 2320.8833, 1686.2612, 5556.895, 136.61429, 124.7619, 2521.75]     |\n",
      "|140|140.0|[19600.0, 4900.0, 2177.7778, 1225.0, 784.0, 544.44446, 400.0]              |[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]          |[140.0, 70.0, 46.666668, 35.0, 28.0, 23.333334, 20.0]        |[6346.6665, 4635.5557, 22983.334, 2648.3333, 1921.1112, 6346.6665, 146.0, 133.33334, 2875.0]       |\n",
      "|152|152.0|[23104.0, 5776.0, 2567.1113, 1444.0, 924.16, 641.77783, 471.51016]         |[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]          |[152.0, 76.0, 50.666668, 38.0, 30.4, 25.333334, 21.714285]   |[7468.2666, 5438.222, 27092.191, 3118.5332, 2258.0444, 7481.2954, 158.51428, 144.7619, 3381.9998]  |\n",
      "|158|158.0|[24964.0, 6241.0, 2773.7778, 1560.25, 998.56, 693.44446, 509.46936]        |[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]          |[158.0, 79.0, 52.666668, 39.5, 31.6, 26.333334, 22.571428]   |[8063.2666, 5863.5557, 29273.262, 3368.0334, 2436.7112, 8083.581, 164.77142, 150.4762, 3650.9285]  |\n",
      "|200|200.0|[40000.0, 10000.0, 4444.4443, 2500.0, 1600.0, 1111.1111, 816.32654]        |[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]          |[200.0, 100.0, 66.666664, 50.0, 40.0, 33.333332, 28.571428]  |[12866.667, 9288.889, 46904.76, 5383.3335, 3877.7776, 12952.381, 208.57143, 190.47618, 5821.4287]  |\n",
      "|202|202.0|[40804.0, 10201.0, 4533.7783, 2550.25, 1632.1602, 1133.4446, 832.73474]    |[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]          |[202.0, 101.0, 67.333336, 50.5, 40.4, 33.666668, 28.857143]  |[13123.267, 9471.556, 47847.547, 5491.0337, 3954.7114, 13212.724, 210.65715, 192.38095, 5937.3574] |\n",
      "|218|218.0|[47524.0, 11881.0, 5280.444, 2970.25, 1900.9598, 1320.111, 969.8775]       |[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]          |[218.0, 109.0, 72.666664, 54.5, 43.6, 36.333332, 31.142857]  |[15267.267, 10996.889, 55727.547, 6391.033, 4597.3774, 15388.724, 227.34285, 207.61905, 6905.928]  |\n",
      "|223|223.0|[49729.0, 12432.25, 5525.445, 3108.0625, 1989.1599, 1381.3612, 1014.87756] |[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]          |[223.0, 111.5, 74.333336, 55.75, 44.6, 37.166668, 31.857143] |[15970.517, 11496.89, 58313.17, 6686.283, 4808.128, 16102.724, 232.55714, 212.38095, 7223.6074]    |\n",
      "|269|269.0|[72361.0, 18090.25, 8040.111, 4522.5625, 2894.44, 2010.0277, 1476.755]     |[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]          |[269.0, 134.5, 89.666664, 67.25, 53.8, 44.833332, 38.42857]  |[23183.316, 16618.22, 84851.88, 9715.383, 6968.594, 23431.182, 280.52856, 256.19046, 10481.393]    |\n",
      "|277|277.0|[76729.0, 19182.25, 8525.445, 4795.5625, 3069.1602, 2131.3613, 1565.8981]  |[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]          |[277.0, 138.5, 92.333336, 69.25, 55.4, 46.166668, 39.57143]  |[24574.518, 17604.889, 89973.89, 10299.783, 7385.1284, 24845.582, 288.87143, 263.80954, 11109.679] |\n",
      "|295|295.0|[87025.0, 21756.25, 9669.445, 5439.0625, 3481.0, 2417.3613, 1776.0204]     |[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]          |[295.0, 147.5, 98.333336, 73.75, 59.0, 49.166668, 42.142857] |[27852.916, 19928.889, 102047.17, 11677.083, 8366.528, 28179.523, 307.64285, 280.9524, 12590.179]  |\n",
      "|314|314.0|[98596.0, 24649.0, 10955.11, 6162.25, 3943.8398, 2738.7776, 2012.1633]     |[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]          |[314.0, 157.0, 104.666664, 78.5, 62.8, 52.333332, 44.857143] |[31536.066, 22538.22, 115615.55, 13224.633, 9468.844, 31926.324, 327.45715, 299.0476, 14253.357]   |\n",
      "|347|347.0|[120409.0, 30102.25, 13378.777, 7525.5625, 4816.3604, 3344.6943, 2457.3267]|[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]          |[347.0, 173.5, 115.666664, 86.75, 69.4, 57.833332, 49.57143] |[38476.516, 27451.555, 141193.89, 16141.283, 11545.461, 38989.582, 361.87143, 330.4762, 17387.18]  |\n",
      "|365|365.0|[133225.0, 33306.25, 14802.777, 8326.5625, 5329.0, 3700.6943, 2718.8774]   |[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]          |[365.0, 182.5, 121.666664, 91.25, 73.0, 60.833332, 52.142857]|[42552.918, 30335.555, 156222.17, 17854.584, 12764.86, 43139.523, 380.64285, 347.61905, 19227.678] |\n",
      "|370|370.0|[136900.0, 34225.0, 15211.111, 8556.25, 5476.0, 3802.7778, 2793.8777]      |[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]          |[370.0, 185.0, 123.333336, 92.5, 74.0, 61.666668, 52.857143] |[43721.668, 31162.223, 160531.55, 18345.834, 13114.444, 44329.523, 385.85715, 352.38095, 19755.357]|\n",
      "|388|388.0|[150544.0, 37636.0, 16727.11, 9409.0, 6021.76, 4181.7773, 3072.3264]       |[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]          |[388.0, 194.0, 129.33333, 97.0, 77.6, 64.666664, 55.42857]   |[48060.266, 34230.22, 176530.77, 20169.533, 14412.044, 48747.582, 404.62857, 369.5238, 21714.143]  |\n",
      "|389|389.0|[151321.0, 37830.25, 16813.445, 9457.5625, 6052.8403, 4203.3613, 3088.1838]|[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]          |[389.0, 194.5, 129.66667, 97.25, 77.8, 64.833336, 55.57143]  |[48307.316, 34404.89, 177441.89, 20273.385, 14485.929, 48999.18, 405.67145, 370.4762, 21825.68]    |\n",
      "+---+-----+---------------------------------------------------------------------------+---------------------------------------------+-------------------------------------------------------------+---------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "== Physical Plan ==\n",
      "*(1) Project [uid#1020, score#1025, genericvectorcoomul(score_list#1026, score_list#1026) AS genericvectorcoomul(score_list, score_list)#1414, genericvectorsemidiff(score_list#1026, score_list#1026) AS genericvectorsemidiff(score_list, score_list)#1415, genericvectorsemisum(score_list#1026, score_list#1026) AS genericvectorsemisum(score_list, score_list)#1416, genericvectormatmul(concat(score_list#1026, [1.0,2.0]), concat([1.0,2.0], score_list#1026)) AS genericvectormatmul(concat(score_list, array(1, 2)), concat(array(1, 2), score_list))#1417]\n",
      "+- *(1) Filter ((isnotnull(score#1025) && uid_type#1023 IN (ut2,ut1)) && NOT (score#1025 = 10.0))\n",
      "   +- *(1) FileScan parquet [uid#1020,uid_type#1023,score#1025,score_list#1026] Batched: false, Format: Parquet, Location: InMemoryFileIndex[hdfs://hacluster/user/v.fedulov/TRG-102772/test_dataset], PartitionFilters: [], PushedFilters: [IsNotNull(score), In(uid_type, [ut2,ut1]), Not(EqualTo(score,10.0))], ReadSchema: struct<uid:string,uid_type:string,score:float,score_list:array<float>>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[uid: string, score: float, genericvectorcoomul(score_list, score_list): array<float>, genericvectorsemidiff(score_list, score_list): array<float>, genericvectorsemisum(score_list, score_list): array<float>, genericvectormatmul(concat(score_list, array(1, 2)), concat(array(1, 2), score_list)): array<float>]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "+---+-------------+--------+--------+---------+-----+--------------------+--------------------+\n",
    "|uid|audience_name|category|uid_type|action_dt|score|          score_list|           score_map|\n",
    "+---+-------------+--------+--------+---------+-----+--------------------+--------------------+\n",
    "| 20|         an20|positive|     ut2|       20| 20.0|[20.0, 10.0, 6.66...|[0 -> 20.0, 1 -> ...|\n",
    "\"\"\"\n",
    "exprs = [sqlfn.expr(expr) for expr in [\n",
    "    \"uid\",\n",
    "    \"score\",\n",
    "    \"coomul(score_list, score_list)\",\n",
    "    \"semidiff(score_list, score_list)\",\n",
    "    \"semisum(score_list, score_list)\",\n",
    "    \"matmul(concat(score_list, array(1, 2)), concat(array(1, 2), score_list))\",\n",
    "]]\n",
    "\n",
    "_df = df.where(\"uid_type in ('ut2', 'ut1')\").select(*exprs).where(\"score != 10\")\n",
    "show(_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### isinf(x); isfinite(x)\n",
    "Сигнатура: `(Atomic) => Boolean`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- uid: string (nullable = true)\n",
      " |-- audience_name: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- uid_type: string (nullable = true)\n",
      " |-- action_dt: long (nullable = true)\n",
      " |-- score: float (nullable = true)\n",
      " |-- score_list: array (nullable = true)\n",
      " |    |-- element: float (containsNull = true)\n",
      " |-- score_map: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: float (valueContainsNull = true)\n",
      "\n",
      "root\n",
      " |-- uid: string (nullable = true)\n",
      " |-- score: float (nullable = true)\n",
      " |-- genericisinf(CAST(uid AS DOUBLE)): boolean (nullable = false)\n",
      " |-- genericisfinite(CAST(uid AS DOUBLE)): boolean (nullable = false)\n",
      " |-- genericisinf(CAST(score AS DOUBLE)): boolean (nullable = false)\n",
      " |-- genericisfinite(CAST(score AS DOUBLE)): boolean (nullable = false)\n",
      "\n",
      "+---+-----+---------------------------------+------------------------------------+-----------------------------------+--------------------------------------+\n",
      "|uid|score|genericisinf(CAST(uid AS DOUBLE))|genericisfinite(CAST(uid AS DOUBLE))|genericisinf(CAST(score AS DOUBLE))|genericisfinite(CAST(score AS DOUBLE))|\n",
      "+---+-----+---------------------------------+------------------------------------+-----------------------------------+--------------------------------------+\n",
      "|20 |20.0 |false                            |true                                |false                              |true                                  |\n",
      "|70 |70.0 |false                            |true                                |false                              |true                                  |\n",
      "|121|121.0|false                            |true                                |false                              |true                                  |\n",
      "|131|131.0|false                            |true                                |false                              |true                                  |\n",
      "|140|140.0|false                            |true                                |false                              |true                                  |\n",
      "|152|152.0|false                            |true                                |false                              |true                                  |\n",
      "|158|158.0|false                            |true                                |false                              |true                                  |\n",
      "|200|200.0|false                            |true                                |false                              |true                                  |\n",
      "|202|202.0|false                            |true                                |false                              |true                                  |\n",
      "|218|218.0|false                            |true                                |false                              |true                                  |\n",
      "|223|223.0|false                            |true                                |false                              |true                                  |\n",
      "|269|269.0|false                            |true                                |false                              |true                                  |\n",
      "|277|277.0|false                            |true                                |false                              |true                                  |\n",
      "|295|295.0|false                            |true                                |false                              |true                                  |\n",
      "|314|314.0|false                            |true                                |false                              |true                                  |\n",
      "|347|347.0|false                            |true                                |false                              |true                                  |\n",
      "|365|365.0|false                            |true                                |false                              |true                                  |\n",
      "|370|370.0|false                            |true                                |false                              |true                                  |\n",
      "|388|388.0|false                            |true                                |false                              |true                                  |\n",
      "|389|389.0|false                            |true                                |false                              |true                                  |\n",
      "+---+-----+---------------------------------+------------------------------------+-----------------------------------+--------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "== Physical Plan ==\n",
      "*(1) Project [uid#1020, score#1025, genericisinf(cast(uid#1020 as double)) AS genericisinf(CAST(uid AS DOUBLE))#1642, genericisfinite(cast(uid#1020 as double)) AS genericisfinite(CAST(uid AS DOUBLE))#1643, genericisinf(cast(score#1025 as double)) AS genericisinf(CAST(score AS DOUBLE))#1644, genericisfinite(cast(score#1025 as double)) AS genericisfinite(CAST(score AS DOUBLE))#1645]\n",
      "+- *(1) Filter ((isnotnull(score#1025) && uid_type#1023 IN (ut2,ut1)) && NOT (score#1025 = 10.0))\n",
      "   +- *(1) FileScan parquet [uid#1020,uid_type#1023,score#1025] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://hacluster/user/v.fedulov/TRG-102772/test_dataset], PartitionFilters: [], PushedFilters: [IsNotNull(score), In(uid_type, [ut2,ut1]), Not(EqualTo(score,10.0))], ReadSchema: struct<uid:string,uid_type:string,score:float>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[uid: string, score: float, genericisinf(CAST(uid AS DOUBLE)): boolean, genericisfinite(CAST(uid AS DOUBLE)): boolean, genericisinf(CAST(score AS DOUBLE)): boolean, genericisfinite(CAST(score AS DOUBLE)): boolean]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "+---+-------------+--------+--------+---------+-----+--------------------+--------------------+\n",
    "|uid|audience_name|category|uid_type|action_dt|score|          score_list|           score_map|\n",
    "+---+-------------+--------+--------+---------+-----+--------------------+--------------------+\n",
    "| 20|         an20|positive|     ut2|       20| 20.0|[20.0, 10.0, 6.66...|[0 -> 20.0, 1 -> ...|\n",
    "\"\"\"\n",
    "df.printSchema()\n",
    "exprs = [sqlfn.expr(expr) for expr in [\n",
    "    \"uid\",\n",
    "    \"score\",\n",
    "    \"isinf(uid)\",\n",
    "    \"isfinite(uid)\",\n",
    "    \"isinf(double(score))\",  # bug? if score is float: codegen failure: java.lang.VerifyError: Expecting a stackmap frame at branch target\n",
    "    \"isfinite(double(score))\",\n",
    "]]\n",
    "\n",
    "_df = df.where(\"uid_type in ('ut2', 'ut1')\").select(*exprs).where(\"score != 10\")\n",
    "show(_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[uid: string, audience_name: string, category: string, uid_type: string, action_dt: bigint, score: float, score_list: array<float>, score_map: map<string,float>]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
